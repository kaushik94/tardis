<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title>Test Report</title>
    <style>body {
	font-family: Helvetica, Arial, sans-serif;
	font-size: 12px;
	/* do not increase min-width as some may use split screens */
	min-width: 800px;
	color: #999;
}

h1 {
	font-size: 24px;
	color: black;
}

h2 {
	font-size: 16px;
	color: black;
}

p {
    color: black;
}

a {
	color: #999;
}

table {
	border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/

#environment td {
	padding: 5px;
	border: 1px solid #E6E6E6;
}

#environment tr:nth-child(odd) {
	background-color: #f6f6f6;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed, .passed .col-result {
	color: green;
}
span.skipped, span.xfailed, span.rerun, .skipped .col-result, .xfailed .col-result, .rerun .col-result {
	color: orange;
}
span.error, span.failed, span.xpassed, .error .col-result, .failed .col-result, .xpassed .col-result  {
	color: red;
}


/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/

/*------------------
 * 1. Table Layout
 *------------------*/

#results-table {
	border: 1px solid #e6e6e6;
	color: #999;
	font-size: 12px;
	width: 100%
}

#results-table th, #results-table td {
	padding: 5px;
	border: 1px solid #E6E6E6;
	text-align: left
}
#results-table th {
	font-weight: bold
}

/*------------------
 * 2. Extra
 *------------------*/

.log:only-child {
	height: inherit
}
.log {
	background-color: #e6e6e6;
	border: 1px solid #e6e6e6;
	color: black;
	display: block;
	font-family: "Courier New", Courier, monospace;
	height: 230px;
	overflow-y: scroll;
	padding: 5px;
	white-space: pre-wrap
}
div.image {
	border: 1px solid #e6e6e6;
	float: right;
	height: 240px;
	margin-left: 5px;
	overflow: hidden;
	width: 320px
}
div.image img {
	width: 320px
}
div.video {
	border: 1px solid #e6e6e6;
	float: right;
	height: 240px;
	margin-left: 5px;
	overflow: hidden;
	width: 320px
}
div.video video {
	overflow: hidden;
	width: 320px;
    height: 240px;
}
.collapsed {
	display: none;
}
.expander::after {
	content: " (show details)";
	color: #BBB;
	font-style: italic;
	cursor: pointer;
}
.collapser::after {
	content: " (hide details)";
	color: #BBB;
	font-style: italic;
	cursor: pointer;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
	cursor: pointer;
}

.sort-icon {
	font-size: 0px;
	float: left;
	margin-right: 5px;
	margin-top: 5px;
	/*triangle*/
	width: 0;
	height: 0;
	border-left: 8px solid transparent;
	border-right: 8px solid transparent;
}

.inactive .sort-icon {
	/*finish triangle*/
	border-top: 8px solid #E6E6E6;
}

.asc.active .sort-icon {
	/*finish triangle*/
	border-bottom: 8px solid #999;
}

.desc.active .sort-icon {
	/*finish triangle*/
	border-top: 8px solid #999;
}
</style></head>
  <body onLoad="init()">
    <script>/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this file,
 * You can obtain one at http://mozilla.org/MPL/2.0/. */


function toArray(iter) {
    if (iter === null) {
        return null;
    }
    return Array.prototype.slice.call(iter);
}

function find(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return elem.querySelector(selector);
}

function find_all(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return toArray(elem.querySelectorAll(selector));
}

function sort_column(elem) {
    toggle_sort_states(elem);
    var colIndex = toArray(elem.parentNode.childNodes).indexOf(elem);
    var key;
    if (elem.classList.contains('numeric')) {
        key = key_num;
    } else if (elem.classList.contains('result')) {
        key = key_result;
    } else {
        key = key_alpha;
    }
    sort_table(elem, key(colIndex));
}

function show_all_extras() {
    find_all('.col-result').forEach(show_extras);
}

function hide_all_extras() {
    find_all('.col-result').forEach(hide_extras);
}

function show_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.remove("collapsed");
    expandcollapse.classList.remove("expander");
    expandcollapse.classList.add("collapser");
}

function hide_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.add("collapsed");
    expandcollapse.classList.remove("collapser");
    expandcollapse.classList.add("expander");
}

function show_filters() {
    var filter_items = document.getElementsByClassName('filter');
    for (var i = 0; i < filter_items.length; i++)
        filter_items[i].hidden = false;
}

function add_collapse() {
    // Add links for show/hide all
    var resulttable = find('table#results-table');
    var showhideall = document.createElement("p");
    showhideall.innerHTML = '<a href="javascript:show_all_extras()">Show all details</a> / ' +
                            '<a href="javascript:hide_all_extras()">Hide all details</a>';
    resulttable.parentElement.insertBefore(showhideall, resulttable);

    // Add show/hide link to each result
    find_all('.col-result').forEach(function(elem) {
        var collapsed = get_query_parameter('collapsed') || 'Passed';
        var extras = elem.parentNode.nextElementSibling;
        var expandcollapse = document.createElement("span");
        if (extras.classList.contains("collapsed")) {
            expandcollapse.classList.add("expander")
        } else if (collapsed.includes(elem.innerHTML)) {
            extras.classList.add("collapsed");
            expandcollapse.classList.add("expander");
        } else {
            expandcollapse.classList.add("collapser");
        }
        elem.appendChild(expandcollapse);

        elem.addEventListener("click", function(event) {
            if (event.currentTarget.parentNode.nextElementSibling.classList.contains("collapsed")) {
                show_extras(event.currentTarget);
            } else {
                hide_extras(event.currentTarget);
            }
        });
    })
}

function get_query_parameter(name) {
    var match = RegExp('[?&]' + name + '=([^&]*)').exec(window.location.search);
    return match && decodeURIComponent(match[1].replace(/\+/g, ' '));
}

function init () {
    reset_sort_headers();

    add_collapse();

    show_filters();

    sort_column(find('.initial-sort'));

    find_all('.sortable').forEach(function(elem) {
        elem.addEventListener("click",
                              function(event) {
                                  sort_column(elem);
                              }, false)
    });

};

function sort_table(clicked, key_func) {
    var rows = find_all('.results-table-row');
    var reversed = !clicked.classList.contains('asc');
    var sorted_rows = sort(rows, key_func, reversed);
    /* Whole table is removed here because browsers acts much slower
     * when appending existing elements.
     */
    var thead = document.getElementById("results-table-head");
    document.getElementById('results-table').remove();
    var parent = document.createElement("table");
    parent.id = "results-table";
    parent.appendChild(thead);
    sorted_rows.forEach(function(elem) {
        parent.appendChild(elem);
    });
    document.getElementsByTagName("BODY")[0].appendChild(parent);
}

function sort(items, key_func, reversed) {
    var sort_array = items.map(function(item, i) {
        return [key_func(item), i];
    });

    sort_array.sort(function(a, b) {
        var key_a = a[0];
        var key_b = b[0];

        if (key_a == key_b) return 0;

        if (reversed) {
            return (key_a < key_b ? 1 : -1);
        } else {
            return (key_a > key_b ? 1 : -1);
        }
    });

    return sort_array.map(function(item) {
        var index = item[1];
        return items[index];
    });
}

function key_alpha(col_index) {
    return function(elem) {
        return elem.childNodes[1].childNodes[col_index].firstChild.data.toLowerCase();
    };
}

function key_num(col_index) {
    return function(elem) {
        return parseFloat(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function key_result(col_index) {
    return function(elem) {
        var strings = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed',
                       'Skipped', 'Passed'];
        return strings.indexOf(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function reset_sort_headers() {
    find_all('.sort-icon').forEach(function(elem) {
        elem.parentNode.removeChild(elem);
    });
    find_all('.sortable').forEach(function(elem) {
        var icon = document.createElement("div");
        icon.className = "sort-icon";
        icon.textContent = "vvv";
        elem.insertBefore(icon, elem.firstChild);
        elem.classList.remove("desc", "active");
        elem.classList.add("asc", "inactive");
    });
}

function toggle_sort_states(elem) {
    //if active, toggle between asc and desc
    if (elem.classList.contains('active')) {
        elem.classList.toggle('asc');
        elem.classList.toggle('desc');
    }

    //if inactive, reset all other functions and add ascending active
    if (elem.classList.contains('inactive')) {
        reset_sort_headers();
        elem.classList.remove('inactive');
        elem.classList.add('active');
    }
}

function is_all_rows_hidden(value) {
  return value.hidden == false;
}

function filter_table(elem) {
    var outcome_att = "data-test-result";
    var outcome = elem.getAttribute(outcome_att);
    class_outcome = outcome + " results-table-row";
    var outcome_rows = document.getElementsByClassName(class_outcome);

    for(var i = 0; i < outcome_rows.length; i++){
        outcome_rows[i].hidden = !elem.checked;
    }

    var rows = find_all('.results-table-row').filter(is_all_rows_hidden);
    var all_rows_hidden = rows.length == 0 ? true : false;
    var not_found_message = document.getElementById("not-found-message");
    not_found_message.hidden = !all_rows_hidden;
}
</script>
    <h1>report.html</h1>
    <p>Report generated on 02-Oct-2020 at 19:55:42 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a> v2.1.1</p>
    <h2>Environment</h2>
    <table id="environment">
      <tr>
        <td>Packages</td>
        <td>{"pluggy": "0.13.1", "py": "1.9.0", "pytest": "5.4.3"}</td></tr>
      <tr>
        <td>Platform</td>
        <td>Darwin-18.7.0-x86_64-i386-64bit</td></tr>
      <tr>
        <td>Plugins</td>
        <td>{"arraydiff": "0.3", "astropy-header": "0.1.2", "cov": "2.10.0", "doctestplus": "0.7.0", "html": "2.1.1", "hypothesis": "5.18.2", "metadata": "1.10.0", "openfiles": "0.5.0", "remotedata": "0.3.1"}</td></tr>
      <tr>
        <td>Python</td>
        <td>3.6.10</td></tr></table>
    <h2>Summary</h2>
    <p>0 tests ran in 5.06 seconds. </p>
    <p class="filter" hidden="true">(Un)check the boxes to filter the results.</p><input checked="true" class="filter" data-test-result="passed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="passed">0 passed</span>, <input checked="true" class="filter" data-test-result="skipped" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="skipped">0 skipped</span>, <input checked="true" class="filter" data-test-result="failed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="failed">0 failed</span>, <input checked="true" class="filter" data-test-result="error" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="error">40 errors</span>, <input checked="true" class="filter" data-test-result="xfailed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xfailed">0 expected failures</span>, <input checked="true" class="filter" data-test-result="xpassed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xpassed">0 unexpected passes</span>
    <h2>Results</h2>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable result initial-sort" col="result">Result</th>
          <th class="sortable" col="name">Test</th>
          <th class="sortable numeric" col="duration">Duration</th>
          <th>Links</th></tr>
        <tr hidden="true" id="not-found-message">
          <th colspan="4">No results found. Try to check the filters</th></tr></thead>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities1]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities2]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities3]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities4]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities5]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities6]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities7]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities8]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities9]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities10]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities11]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities12]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities13]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities14]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities15]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities16]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities17]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities18]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_spectrum[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>&gt;               reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/><br/>conftest.py:155: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/><br/>path = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, complevel = None, complib = None, fletcher32 = False, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def __init__(self, path, mode=None, complevel=None, complib=None,<br/>                 fletcher32=False, **kwargs):<br/>    <br/>        if &#x27;format&#x27; in kwargs:<br/>            raise ValueError(&#x27;format is not a defined argument for HDFStore&#x27;)<br/>    <br/>        try:<br/>            import tables  # noqa<br/>        except ImportError as ex:  # pragma: no cover<br/>            raise ImportError(&#x27;HDFStore requires PyTables, &quot;{ex!s}&quot; problem &#x27;<br/>                              &#x27;importing&#x27;.format(ex=ex))<br/>    <br/>        if complib is not None and complib not in tables.filters.all_complibs:<br/>            raise ValueError(<br/>                &quot;complib only supports {libs} compression.&quot;.format(<br/>                    libs=tables.filters.all_complibs))<br/>    <br/>        if complib is None and complevel is not None:<br/>            complib = tables.filters.default_complib<br/>    <br/>        self._path = _stringify_path(path)<br/>        if mode is None:<br/>            mode = &#x27;a&#x27;<br/>        self._mode = mode<br/>        self._handle = None<br/>        self._complevel = complevel if complevel else 0<br/>        self._complib = complib<br/>        self._fletcher32 = fletcher32<br/>        self._filters = None<br/>&gt;       self.open(mode=mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:488: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5<br/>, mode = &#x27;r&#x27;, kwargs = {}<br/>tables = &lt;module &#x27;tables&#x27; from &#x27;/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/__init__.py&#x27;&gt;<br/><br/>    def open(self, mode=&#x27;a&#x27;, **kwargs):<br/>        &quot;&quot;&quot;<br/>        Open the file in the specified mode<br/>    <br/>        Parameters<br/>        ----------<br/>        mode : {&#x27;a&#x27;, &#x27;w&#x27;, &#x27;r&#x27;, &#x27;r+&#x27;}, default &#x27;a&#x27;<br/>            See HDFStore docstring or tables.open_file for info about modes<br/>        &quot;&quot;&quot;<br/>        tables = _tables()<br/>    <br/>        if self._mode != mode:<br/>    <br/>            # if we are changing a write mode to read, ok<br/>            if self._mode in [&#x27;a&#x27;, &#x27;w&#x27;] and mode in [&#x27;r&#x27;, &#x27;r+&#x27;]:<br/>                pass<br/>            elif mode in [&#x27;w&#x27;]:<br/>    <br/>                # this would truncate, raise here<br/>                if self.is_open:<br/>                    raise PossibleDataLossError(<br/>                        &quot;Re-opening the file [{0}] with mode [{1}] &quot;<br/>                        &quot;will delete the current file!&quot;<br/>                        .format(self._path, self._mode)<br/>                    )<br/>    <br/>            self._mode = mode<br/>    <br/>        # close and reopen the handle<br/>        if self.is_open:<br/>            self.close()<br/>    <br/>        if self._complevel and self._complevel &gt; 0:<br/>            self._filters = _tables().Filters(self._complevel, self._complib,<br/>                                              fletcher32=self._fletcher32)<br/>    <br/>        try:<br/>&gt;           self._handle = tables.open_file(self._path, self._mode, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pandas/io/pytables.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}<br/><br/>    def open_file(filename, mode=&quot;r&quot;, title=&quot;&quot;, root_uep=&quot;/&quot;, filters=None,<br/>                  **kwargs):<br/>        &quot;&quot;&quot;Open a PyTables (or generic HDF5) file and return a File object.<br/>    <br/>        Parameters<br/>        ----------<br/>        filename : str<br/>            The name of the file (supports environment variable expansion).<br/>            It is suggested that file names have any of the .h5, .hdf or<br/>            .hdf5 extensions, although this is not mandatory.<br/>        mode : str<br/>            The mode to open the file. It can be one of the<br/>            following:<br/>    <br/>                * *&#x27;r&#x27;*: Read-only; no data can be modified.<br/>                * *&#x27;w&#x27;*: Write; a new file is created (an existing file<br/>                  with the same name would be deleted).<br/>                * *&#x27;a&#x27;*: Append; an existing file is opened for reading and<br/>                  writing, and if the file does not exist it is created.<br/>                * *&#x27;r+&#x27;*: It is similar to &#x27;a&#x27;, but the file must already<br/>                  exist.<br/>    <br/>        title : str<br/>            If the file is to be created, a TITLE string attribute will be<br/>            set on the root group with the given value. Otherwise, the<br/>            title will be read from disk, and this will not have any effect.<br/>        root_uep : str<br/>            The root User Entry Point. This is a group in the HDF5 hierarchy<br/>            which will be taken as the starting point to create the object<br/>            tree. It can be whatever existing group in the file, named by<br/>            its HDF5 path. If it does not exist, an HDF5ExtError is issued.<br/>            Use this if you do not want to build the *entire* object tree,<br/>            but rather only a *subtree* of it.<br/>    <br/>            .. versionchanged:: 3.0<br/>               The *rootUEP* parameter has been renamed into *root_uep*.<br/>    <br/>        filters : Filters<br/>            An instance of the Filters (see :ref:`FiltersClassDescr`) class<br/>            that provides information about the desired I/O filters<br/>            applicable to the leaves that hang directly from the *root group*,<br/>            unless other filter properties are specified for these leaves.<br/>            Besides, if you do not specify filter properties for child groups,<br/>            they will inherit these ones, which will in turn propagate to<br/>            child nodes.<br/>    <br/>        Notes<br/>        -----<br/>        In addition, it recognizes the (lowercase) names of parameters<br/>        present in :file:`tables/parameters.py` as additional keyword<br/>        arguments.<br/>        See :ref:`parameter_files` for a detailed info on the supported<br/>        parameters.<br/>    <br/>        .. note::<br/>    <br/>            If you need to deal with a large number of nodes in an<br/>            efficient way, please see :ref:`LRUOptim` for more info and<br/>            advices about the integrated node cache engine.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        # XXX filename normalization ??<br/>    <br/>        # Check already opened files<br/>        if _FILE_OPEN_POLICY == &#x27;strict&#x27;:<br/>            # This policy do not allows to open the same file multiple times<br/>            # even in read-only mode<br/>            if filename in _open_files:<br/>                raise ValueError(<br/>                    &quot;The file &#x27;%s&#x27; is already opened.  &quot;<br/>                    &quot;Please close it before reopening.  &quot;<br/>                    &quot;HDF5 v.%s, FILE_OPEN_POLICY = &#x27;%s&#x27;&quot; % (<br/>                        filename, utilsextension.get_hdf5_version(),<br/>                        _FILE_OPEN_POLICY))<br/>        else:<br/>            for filehandle in _open_files.get_handlers_by_name(filename):<br/>                omode = filehandle.mode<br/>                # &#x27;r&#x27; is incompatible with everything except &#x27;r&#x27; itself<br/>                if mode == &#x27;r&#x27; and omode != &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;not in read-only mode (as requested).&quot; % filename)<br/>                # &#x27;a&#x27; and &#x27;r+&#x27; are compatible with everything except &#x27;r&#x27;<br/>                elif mode in (&#x27;a&#x27;, &#x27;r+&#x27;) and omode == &#x27;r&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened, but &quot;<br/>                        &quot;in read-only mode.  Please close it before &quot;<br/>                        &quot;reopening in append mode.&quot; % filename)<br/>                # &#x27;w&#x27; means that we want to destroy existing contents<br/>                elif mode == &#x27;w&#x27;:<br/>                    raise ValueError(<br/>                        &quot;The file &#x27;%s&#x27; is already opened.  Please &quot;<br/>                        &quot;close it before reopening in write mode.&quot; % filename)<br/>    <br/>        # Finally, create the File instance, and return it<br/>&gt;       return File(filename, mode, title, root_uep, filters, **kwargs)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:320: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;[AttributeError(&quot;&#x27;File&#x27; object has no attribute &#x27;isopen&#x27;&quot;,) raised in repr()] File object at 0x13ba9a278&gt;, filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;<br/>mode = &#x27;r&#x27;, title = &#x27;&#x27;, root_uep = &#x27;/&#x27;, filters = None, kwargs = {}, params = {&#x27;BOUNDS_MAX_SIZE&#x27;: 1048576, &#x27;BOUNDS_MAX_SLOTS&#x27;: 4096, &#x27;BUFFER_TIMES&#x27;: 100, &#x27;CHUNK_CACHE_NELMTS&#x27;: 521, ...}<br/><br/>    def __init__(self, filename, mode=&quot;r&quot;, title=&quot;&quot;,<br/>                 root_uep=&quot;/&quot;, filters=None, **kwargs):<br/>    <br/>        self.filename = filename<br/>        &quot;&quot;&quot;The name of the opened file.&quot;&quot;&quot;<br/>    <br/>        self.mode = mode<br/>        &quot;&quot;&quot;The mode in which the file was opened.&quot;&quot;&quot;<br/>    <br/>        if mode not in (&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27;, &#x27;w&#x27;):<br/>            raise ValueError(&quot;invalid mode string ``%s``. Allowed modes are: &quot;<br/>                             &quot;&#x27;r&#x27;, &#x27;r+&#x27;, &#x27;a&#x27; and &#x27;w&#x27;&quot; % mode)<br/>    <br/>        # Get all the parameters in parameter file(s)<br/>        params = dict([(k, v) for k, v in six.iteritems(parameters.__dict__)<br/>                       if k.isupper() and not k.startswith(&#x27;_&#x27;)])<br/>        # Update them with possible keyword arguments<br/>        if [k for k in kwargs if k.isupper()]:<br/>            warnings.warn(&quot;The use of uppercase keyword parameters is &quot;<br/>                          &quot;deprecated&quot;, DeprecationWarning)<br/>    <br/>        kwargs = dict([(k.upper(), v) for k, v in six.iteritems(kwargs)])<br/>        params.update(kwargs)<br/>    <br/>        # If MAX_ * _THREADS is not set yet, set it to the number of cores<br/>        # on this machine.<br/>    <br/>        if params[&#x27;MAX_NUMEXPR_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_NUMEXPR_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        if params[&#x27;MAX_BLOSC_THREADS&#x27;] is None:<br/>            params[&#x27;MAX_BLOSC_THREADS&#x27;] = detect_number_of_cores()<br/>    <br/>        self.params = params<br/>    <br/>        # Now, it is time to initialize the File extension<br/>&gt;       self._g_new(filename, mode, **params)<br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/file.py:784: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>&gt;   ???<br/><br/>tables/hdf5extension.pyx:371: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>filename = &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, mode = &#x27;r&#x27;<br/><br/>    def check_file_access(filename, mode=&#x27;r&#x27;):<br/>        &quot;&quot;&quot;Check for file access in the specified `mode`.<br/>    <br/>        `mode` is one of the modes supported by `File` objects.  If the file<br/>        indicated by `filename` can be accessed using that `mode`, the<br/>        function ends successfully.  Else, an ``IOError`` is raised<br/>        explaining the reason of the failure.<br/>    <br/>        All this paraphernalia is used to avoid the lengthy and scaring HDF5<br/>        messages produced when there are problems opening a file.  No<br/>        changes are ever made to the file system.<br/>    <br/>        &quot;&quot;&quot;<br/>    <br/>        if mode == &#x27;r&#x27;:<br/>            # The file should be readable.<br/>            if not os.access(filename, os.F_OK):<br/>&gt;               raise IOError(&quot;``%s`` does not exist&quot; % (filename,))<br/><span class="error">E               OSError: ``/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5`` does not exist</span><br/><br/>/Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/tables/utils.py:157: OSError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>request = &lt;SubRequest &#x27;reference&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__-model_quantities0]&gt;&gt;<br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...erence_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5&#x27;, &#x27;setup_name&#x27;: &#x27;__pycache__&#x27;}<br/><br/>    @pytest.fixture(scope=&quot;class&quot;)<br/>    def reference(request, data_path):<br/>        &quot;&quot;&quot;Fixture to ingest reference data for slow test from already available<br/>        HDF file. All data is unpacked as a collection of ``pd.Series`` and<br/>        ``pd.DataFrames`` in a ``pd.HDFStore`` object and returned away.<br/>    <br/>        Assumed that ``data_path[&#x27;reference_path&#x27;]`` is a valid HDF file<br/>        containing the reference dath for a particular setup.<br/>        &quot;&quot;&quot;<br/>        # Reference data need not be loaded and provided if current test run itself<br/>        # generates new reference data.<br/>        if request.config.getoption(&quot;--generate-reference&quot;):<br/>            return<br/>        else:<br/>            try:<br/>                reference = pd.HDFStore(data_path[&quot;reference_path&quot;], &quot;r&quot;)<br/>            except IOError:<br/>                raise IOError(<br/>                    &quot;Reference file {0} does not exist and is needed&quot;<br/>&gt;                   &quot; for the tests&quot;.format(data_path[&quot;reference_path&quot;])<br/>                )<br/><span class="error">E               OSError: Reference file /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/__pycache__.h5 does not exist and is needed for the tests</span><br/><br/>conftest.py:159: OSError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]::setup</td>
          <td class="col-duration">0.34</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/> -----------------------------Captured stdout setup------------------------------ <br/>[[1mpy.warnings         [0m][[1;33mWARNING[0m]  /Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pluggy/manager.py:87: PerformanceWarning: indexing past lexsort depth may impact performance.
  firstresult=hook.spec.opts.get(&quot;firstresult&quot;) if hook.spec else False,
 ([1mwarnings.py[0m:99)
[[1mtardis.io.atom_data.base[0m][[1;37mINFO[0m   ]  Read Atom Data with UUID=6f7b09e887a311e7a06b246e96350010 and MD5=864f1753714343c41f99cb065710cace. ([1mbase.py[0m:187)
[[1mtardis.io.atom_data.base[0m][[1;37mINFO[0m   ]  Non provided atomic data: synpp_refs, photoionization_data ([1mbase.py[0m:193)
<br/> -------------------------------Captured log setup------------------------------- <br/>[33mWARNING [0m py.warnings:warnings.py:99 /Users/ghost/anaconda2/envs/tardis/lib/python3.6/site-packages/pluggy/manager.py:87: PerformanceWarning: indexing past lexsort depth may impact performance.
  firstresult=hook.spec.opts.get(&quot;firstresult&quot;) if hook.spec else False,

[32mINFO    [0m tardis.io.atom_data.base:base.py:187 Read Atom Data with UUID=6f7b09e887a311e7a06b246e96350010 and MD5=864f1753714343c41f99cb065710cace.
[32mINFO    [0m tardis.io.atom_data.base:base.py:193 Non provided atomic data: synpp_refs, photoionization_data<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities1]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities2]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities3]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities4]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities5]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities6]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities7]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities8]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities9]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities10]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities11]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities12]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities13]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities14]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities15]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities16]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities17]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities18]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tardis/tests/integration_tests/test_integration.py::TestIntegration::test_spectrum[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7]::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;tardis.tests.integration_tests.test_integration.TestIntegration object at 0x13b9f4c88&gt;<br/>request = &lt;SubRequest &#x27;setup&#x27; for &lt;Function test_model_quantities[/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7-model_quantities0]&gt;&gt;<br/>reference = &lt;class &#x27;pandas.io.pytables.HDFStore&#x27;&gt;<br/>File path: /Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5<br/><br/>data_path = {&#x27;atom_data_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis-refdata/&#x27;, &#x27;config_dirpath&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardi...on_tests/w7&#x27;, &#x27;reference_path&#x27;: &#x27;/Users/ghost/Desktop/tardis/tardis/tests/integration_tests/w7.h5&#x27;, &#x27;setup_name&#x27;: &#x27;w7&#x27;}<br/><br/>    @classmethod<br/>    @pytest.fixture(scope=&quot;class&quot;, autouse=True)<br/>    def setup(self, request, reference, data_path):<br/>        &quot;&quot;&quot;<br/>        This method does initial setup of creating configuration and performing<br/>        a single run of integration test.<br/>        &quot;&quot;&quot;<br/>        # Get capture manager<br/>        capmanager = request.config.pluginmanager.getplugin(&quot;capturemanager&quot;)<br/>    <br/>        # The last component in dirpath can be extracted as name of setup.<br/>        self.name = data_path[&quot;setup_name&quot;]<br/>    <br/>        self.config_file = os.path.join(<br/>            data_path[&quot;config_dirpath&quot;], &quot;config.yml&quot;<br/>        )<br/>    <br/>        # A quick hack to use atom data per setup. Atom data is ingested from<br/>        # local HDF or downloaded and cached from a url, depending on data_path<br/>        # keys.<br/>        atom_data_name = yaml.load(open(self.config_file), Loader=yaml.CLoader)[<br/>            &quot;atom_data&quot;<br/>        ]<br/>    <br/>        # Get the path to HDF file:<br/>        atom_data_filepath = os.path.join(<br/>            data_path[&quot;atom_data_path&quot;], atom_data_name<br/>        )<br/>    <br/>        # Load atom data file separately, pass it for forming tardis config.<br/>        self.atom_data = AtomData.from_hdf(atom_data_filepath)<br/>    <br/>        # Check whether the atom data file in current run and the atom data<br/>        # file used in obtaining the reference data are same.<br/>        # TODO: hard coded UUID for kurucz atom data file, generalize it later.<br/>        # kurucz_data_file_uuid1 = &quot;5ca3035ca8b311e3bb684437e69d75d7&quot;<br/>        # assert self.atom_data.uuid1 == kurucz_data_file_uuid1<br/>    <br/>        # Create a Configuration through yaml file and atom data.<br/>        tardis_config = Configuration.from_yaml(self.config_file)<br/>    <br/>        # Check whether current run is with less packets.<br/>        if request.config.getoption(&quot;--less-packets&quot;):<br/>            less_packets = request.config.integration_tests_config[<br/>                &quot;less_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;no_of_packets&quot;] = less_packets[<br/>                &quot;no_of_packets&quot;<br/>            ]<br/>            tardis_config[&quot;montecarlo&quot;][&quot;last_no_of_packets&quot;] = less_packets[<br/>                &quot;last_no_of_packets&quot;<br/>            ]<br/>    <br/>        # We now do a run with prepared config and get the simulation object.<br/>        self.result = Simulation.from_config(<br/>&gt;           tardis_config, atom_data=self.atom_data<br/>        )<br/><br/>test_integration.py:132: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>../../simulation/base.py:527: in from_config<br/>    model = Radial1DModel.from_config(config)<br/>../../model/base.py:461: in from_config<br/>    electron_densities=electron_densities)<br/>../../io/util.py:197: in __new__<br/>    instance.__init__(*args, **kwargs)<br/>../../model/base.py:86: in __init__<br/>    self.v_boundary_outer = v_boundary_outer<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;tardis.model.base.Radial1DModel object at 0x13c0ca2e8&gt;, value = &lt;Quantity 3.5e+09 cm / s&gt;<br/><br/>    @v_boundary_outer.setter<br/>    def v_boundary_outer(self, value):<br/>        if value is not None:<br/>            if value &gt; 0 * u.km/u.s:<br/>                value = u.Quantity(value, self.v_boundary_outer.unit)<br/>                if value &lt; self.v_boundary_inner:<br/>                    raise ValueError(&#x27;v_boundary_outer must not be smaller than &#x27;<br/>                                     &#x27;v_boundary_inner.&#x27;)<br/>                if value &lt; self.raw_velocity[0]:<br/>                    raise ValueError(&#x27;v_boundary_outer is outside of &#x27;<br/>                                     &#x27;the model range.&#x27;)<br/>                if value &gt; self.raw_velocity[-1]:<br/>&gt;                   raise ValueError(&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, value, self.raw_velocity[-1], self.raw_velocity)<br/><span class="error">E                   ValueError: (&#x27;v_boundary_outer is larger than the largest shell in the model.&#x27;, &lt;Quantity 3.5e+09 cm / s&gt;, &lt;Quantity 2.e+09 cm / s&gt;, &lt;Quantity [1.10e+09, 1.13e+09, 1.16e+09, 1.19e+09, 1.22e+09, 1.25e+09,</span><br/><span class="error">E                              1.28e+09, 1.31e+09, 1.34e+09, 1.37e+09, 1.40e+09, 1.43e+09,</span><br/><span class="error">E                              1.46e+09, 1.49e+09, 1.52e+09, 1.55e+09, 1.58e+09, 1.61e+09,</span><br/><span class="error">E                              1.64e+09, 1.67e+09, 1.70e+09, 1.73e+09, 1.76e+09, 1.79e+09,</span><br/><span class="error">E                              1.82e+09, 1.85e+09, 1.88e+09, 1.91e+09, 1.94e+09, 1.97e+09,</span><br/><span class="error">E                              2.00e+09] cm / s&gt;)</span><br/><br/>../../model/base.py:320: ValueError<br/></div></td></tr></tbody></table></body></html>